# SwEnt M2 Team Grading Report

The M2 feedback provides an opportunity to give you, as a team, formal feedback on how you are performing in the project. By now, you should be building upon the foundations set in M1, achieving greater autonomy and collaboration within the team. This is meant to complement the informal, ungraded feedback from your coaches given during the weekly meetings or asynchronously on Discord, email, etc.

The feedback focuses on how well your team has applied good software engineering practices, delivered user value, and collaborated effectively. We assessed the quality and maintainability of your implementation, the clarity of your design, and the consistency of your delivery and teamwork across Sprints. An important component is how much you have progressed since the previous milestone. You can find the evaluation criteria in the [M2 Deliverables](https://github.com/swent-epfl/public/blob/main/project/M2.md) document. As mentioned in the past, the standards for M2 are elevated relative to M1, and this progression will continue into M3.

## Yellow Belt

You qualified for a Yellow Belt ðŸ¥‹ðŸŸ¡ and got a final grade of 4.33/6 for M2. Good start! Keep practicing to improve. 

We looked at several aspects, grouped into six categories. Here is the breakdown of the points you earned:

| Metric                                   | **Points Earned**              | **Weight** | **Feedback**                              |
|------------------------------------------|--------------------------------|------------|-------------------------------------------|
| **Implementation (APK, code quality)**   | 4.5 out of 6 | 40%        | [See Details](#implementation-apk-code-quality) |
| **Features**                             | 3.16 out of 6   | 20%        | [See Details](#features)                  |
| **Figma and Architecture Diagram**       | 5.25 out of 6 | 10%     | [See Details](#figma-and-architecture-diagram) |
| **Sprint Backlog & Product Backlog**     | 4.75 out of 6    | 10%        | [See Details](#sprint-backlog--product-backlog) |
| **Scrum Process (documents, autonomy)**  | 6 out of 6 | 10%       | [See Details](#scrum-process-documents-autonomy) |
| **Consistent Delivery of Value**         | 3 out of 6 | 10%      | [See Details](#consistent-delivery-of-value) |
| **Final Grade**                          | **4.33 out of 6**   |            |                                           |

In addition to the feedback you received from the coaches during the Sprints, you will find some extra feedback below.

---

## Implementation (APK, code quality)

We evaluated your APKâ€™s functionality, stability, and user experience, along with the quality and consistency of your code. We also reviewed your CI setup, Sonar integration, and tests, including the presence of at least two meaningful end-to-end tests and the line coverage achieved.

The APK has many issues that affect the user experience. Here is a list of some issues found:
- The association and events data are hardcoded. Thus, all association details screens show the ESN Lausanne association regardless on which association you choose in the list.
- The state that note whether you want to see all events/association or only the one you subscribed to is not rememberable. Thus, when we are in the association or event details screen, and we use the go back button, it always go back to the subscribed tab, even if we were in the other one. Similarly, when we are in the home screen, in the "all events" tab, and we decide to use landscape mode, the tab change and goes back to the subscribed one.
- We cannot click on upcoming events in the association detail page, to see the details of the event.
- The images in the list of associations are not loaded.
- The subscription to an association does not work, we cannot see the association in the subscribed tab and if we reload, we are not subscribed anymore.
- The parameter page does not seem to be implemented yet, there is a superposed button "Sign out" on a text.

Moreover, there is only one meaningful end-to-end-test that is implemented, and it would be hard to envisage a second one since there is no complete features yet.

There are also 4 unresolved and unaccepted issues in the sonar cloud analysis. 

For this part, you received 4.5 points out of a maximum of 6.

## Features

We evaluated the features implemented in this milestone. We looked for the completion of at least one epic, as well as the use of at least one public cloud service, one phone sensor, and a concept of authentication.
We assessed how well the implemented features align with the appâ€™s objectives, integrate with existing functionality, and contribute to delivering clear user value.

The events and associations data seems to be hardcoded, thus there is no real use of a public cloud service.

Additionally, some revelant features exists, but it does not constitue a complete epic. The biggest feature that is available for now is the ability to see the events and associations details, but we cannot create any events or association, nor beeing able to interact with existed events or association, which limit the value of the app.

For this part, you received 3.16 points out of a maximum of 6.

## Figma and Architecture Diagram

We evaluated whether your Figma and architecture diagram accurately reflect the current implementation of the app and how well they align with the app's functionality and structure. 

The figma follows the current structure of the app, but doesn't have designs for important features such as screens for the event organizers. This would be good for future features.

For this part, you received 5.25 points out of a maximum of 6.

## Sprint Backlog & Product Backlog

We assessed the structure and clarity of your Sprint and Product Backlogs and how you used them. We looked at whether your tasks are well defined, appropriately sized, and aligned with user stories; whether the Product Backlog is well organized and value-driven; and whether the Sprint Backlog is continuously updated and demonstrates good planning and prioritization.

The tasks can be linked to the user stories to be able to track the progress of implementation of each of them. 
Moreover, the task #190 for sprint 6 is missing some description to provide more details about it. There is also a redundant task (issues #13 and #193).

Concerning the product backlog, there are some user stories (like #125) that seems to be implemented but are not moved to the "Done" column. There is also no epic written in the scrum board.

For this part, you received 4.75 points out of a maximum of 6.

## Scrum Process (documents, autonomy)

We evaluated your ability to autonomously run and document the Scrum process. We looked at how well you documented your team Stand-Ups and Retrospectives for each Sprint. We also assessed your level of autonomy in organizing and conducting these ceremonies, defining and prioritizing user stories in your Product Backlog, and planning well-scoped Sprint tasks that lead to concrete, valuable increments.

All the scrum documents are correctly filled out with blockers and solutions. The meetings go well, no need for coaches to intervene.

For this part, you received 6 points out of a maximum of 6.

## Consistent Delivery of Value

We reviewed your teamâ€™s ability to deliver meaningful increments of value at the end of each Sprint.  
We assessed whether your progress was steady, visible, and tied to concrete user value and app functionality, in line with your Product Backlog objectives.

Each sprints deliver some code improvements, but the app does not always gain value.

For this part, you received 3 points out of a maximum of 6.

## Summary

Your team grade for milestone M2 is 4.33/6. If you are interested in how this fits into the bigger grading scheme, please see [project README](https://github.com/swent-epfl/public/blob/main/project/README.md) and the [course README](https://github.com/swent-epfl/public/blob/main/README.md).

Your coaches will be happy to discuss the above feedback in more detail.

Keep up the good work and good luck for the next milestone!